{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Most basic model query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith can help with testing in the following ways:\\n\\n1. Automated testing: Langsmith can help create automated tests for your software, allowing you to quickly and efficiently test the functionality of your code.\\n\\n2. Test case generation: Langsmith can generate test cases based on your code, helping you to identify potential edge cases and areas of weakness in your software.\\n\\n3. Code coverage analysis: Langsmith can analyze your code to determine how much of it is covered by your tests, helping you to identify areas that may need additional testing.\\n\\n4. Performance testing: Langsmith can help with performance testing, allowing you to identify bottlenecks and optimize the performance of your software.\\n\\n5. Integration testing: Langsmith can assist with integration testing, ensuring that different components of your software work together seamlessly.\\n\\nOverall, Langsmith can help streamline the testing process, improve the quality of your software, and ultimately save you time and resources in the long run.', response_metadata={'token_usage': {'completion_tokens': 189, 'prompt_tokens': 15, 'total_tokens': 204}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0e12acd9-5e1a-41d1-9e96-d23e9ce0f336-0', usage_metadata={'input_tokens': 15, 'output_tokens': 189, 'total_tokens': 204})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 - Invoke the model\n",
    "llm.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 - Use a prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 - (Optional) Output parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith is an AI-powered tool that can assist with testing in various ways. Here are some ways Langsmith can help with testing:\\n\\n1. Test case generation: Langsmith can automatically generate test cases based on the code, requirements, or specifications provided to it. This can help in generating a comprehensive set of test cases quickly and efficiently.\\n\\n2. Test data generation: Langsmith can help in generating test data that covers different scenarios and edge cases, helping in thorough testing of the software application.\\n\\n3. Test automation: Langsmith can be integrated with test automation frameworks to automate the execution of test cases. This can help in speeding up the testing process and ensuring consistent test execution.\\n\\n4. Code analysis: Langsmith can analyze the codebase to identify potential bugs, security vulnerabilities, or performance issues. This can help in improving the overall quality of the code and reducing the number of defects in the software.\\n\\n5. Test coverage analysis: Langsmith can analyze the test coverage of the codebase and identify areas that are not covered by existing test cases. This can help in improving the test coverage and ensuring that all parts of the code are adequately tested.\\n\\nOverall, Langsmith can be a valuable tool in the testing process, helping testers to automate repetitive tasks, generate test cases and data, analyze code, and improve test coverage.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Retrieval chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"What's Going on With Dell Stock?\",\n",
       " 'Should You Buy Dell Stock on the Dip?',\n",
       " 'Dell shares slump as heavy AI investments expected to dent margin',\n",
       " 'Dell Fails To Impress With Its AI Business Progress',\n",
       " 'Dell Falls Most Since 2018 After AI Server Sales Disappoint',\n",
       " 'Midday movers: Autodesk, GameStop rise, Dell falls By Investing.com',\n",
       " 'Dell’s best-selling gaming laptop is $200 off today',\n",
       " 'How Much Can Dell Profit From The AI Wave?',\n",
       " 'Dell earnings reveal sluggish enterprise AI adoption',\n",
       " \"Dell's new XPS 13 laptop running a Snapdragon X Elite CPU has 27 hours of battery life, 9 more than the Intel version\",\n",
       " 'Texans WR Tank Dell opens up about Florida shooting',\n",
       " 'AI Benefits Without Cost to Planet: Does Dell Have Answer?',\n",
       " 'Dell Technologies Delivers First Quarter Fiscal 2025 Financial Results',\n",
       " \"Massive Dell summer sale is live - I've picked the 5 best laptop deals worth buying\",\n",
       " \"Texans' Tank Dell Reflects on Being Injured in Shooting: 'Wrong Place, Wrong Time'\",\n",
       " \"Michael Dell's net worth sinks the most in a single day, falling by $11.7 billion after shares of his company suffer record ...\",\n",
       " 'High school baseball success continues to stack up for Dell Rapids',\n",
       " 'Is Most-Watched Stock Dell Technologies Inc. (DELL) Worth Betting on Now?',\n",
       " 'Nutanix reports solid revenue rise, signs Dell deal to aid VMware migration – Blocks and Files',\n",
       " 'Dell Stock Plunges Despite Q1 Beat: What To Know',\n",
       " 'Tank Dell shooting: Texans star speaks publicly for first time',\n",
       " \"Dell's stock plummets as rising AI server demand eats away at its gross margin, but AI boosts NetApp\",\n",
       " \"What's Going on With Dell Stock?\",\n",
       " 'Dell launches PowerStore Prime and hints at PowerScale AI boost',\n",
       " 'Why Dell Stock Plunged Today',\n",
       " 'Dell Stock Falls On Mixed Q1 Earnings Report',\n",
       " \"4 Key Takeaways From Dell Technologies' Earnings Call\",\n",
       " \"Dell Escapes Nvidia's Shadow as Its Own AI Tailwinds Accelerate\",\n",
       " \"What You Need To Know Ahead of Dell's Earnings Report\",\n",
       " 'Dell Stock Falls as Earnings, Revenue Beat on Surging AI Server Demand Fails To Impress',\n",
       " \"Dell's profit, margin hurt by higher AI costs, shares slump\",\n",
       " 'Dell Stock Notches Record High On AI Momentum',\n",
       " 'Dell XPS 14 vs. Apple MacBook Pro 14: Which laptop is best for you?',\n",
       " \"Shares of Dell fall 18% as AI servers are sold at 'near-zero margins'\",\n",
       " 'Dell shares fall despite growing AI server business',\n",
       " 'Texans WR Tank Dell speaks publicly for first time since shooting',\n",
       " \"Dell Latitude 7450 Ultralight review: A mobile worker's best friend\",\n",
       " 'Stock Market Retreats As Salesforce, Dell Lead Earnings Losers: Weekly Review',\n",
       " 'Tech stock prices today: Salesforce, Dell, Adobe, Microsoft decline',\n",
       " \"C.J. Stroud 'started tearing up' when he heard Tank Dell was shot\",\n",
       " \"Dell Should Keep Shining in Nvidia's Halo\",\n",
       " 'Dell expects memory and SSD prices to jump an additional 20% this year',\n",
       " 'Winning Culture: Dell Rapids wins 3 of 4 State B Baseball Titles',\n",
       " 'Dell Technologies Inc. (DELL) Q1 2025 Earnings Call Transcript',\n",
       " 'Dell Stock Plummets As Earnings Lag AI Sales Growth',\n",
       " \"Michael Dell's Wealth Plummets by $11.7 Billion as Dell Technologies Shares Tumble\",\n",
       " 'This Analyst With 87% Accuracy Rate Sees 26% Upside In Dell Technologies - Here Are 5 Stock Picks For May',\n",
       " 'The Best Dell & Alienware Deals and Coupons: Gaming Laptops, PCs, Monitors, and More',\n",
       " 'Dell Suffers Worst Day Since 2018 LeapRate',\n",
       " 'DELL shares tumble as solid results, AI server orders fail to satisfy investors By Investing.com',\n",
       " \"Dell's Earnings Disappoint: Is There Hope in AI?\",\n",
       " 'Analysts reboot Dell stock price targets ahead of earnings',\n",
       " \"What's Going On With Dell Technologies Stock Thursday? - Dell Technologies (NYSE:DELL)\",\n",
       " \"Lenovo claims Dell has run off the VxRails and can't sell hyperconverged VMware\",\n",
       " 'Best Dell laptop deals: Cheap laptops starting at $280',\n",
       " 'Cubs rally late to take down Dell Rapids PBR',\n",
       " 'Power Outage in Rio Dell',\n",
       " 'Enhancing data storage efficiency and performance with Dell',\n",
       " 'Dell Rapids rolls through playoffs to fourth title',\n",
       " 'Should You Buy Dell Stock Before May 30?',\n",
       " 'Dell Inspiron 16 crashes to an incredible $540 with this coupon code',\n",
       " '\"That sh*t popped off out of nowhere\" - Tank Dell breaks silence on shooting incident in Sanford bar',\n",
       " \"In one day, Michael Dell's wealth dropped by $11.7 billion\",\n",
       " 'Stocks making the biggest moves premarket: Dell Technologies, Ulta Beauty, Ambarella, Gap and more',\n",
       " 'Should You Buy Dell Stock Before May 30?',\n",
       " 'Should You Buy Dell Stock on the Dip?',\n",
       " 'Top Stock Movers Now: Dell, Gap, VF Corp., and More',\n",
       " 'Watch GPS, PD, VEEV, MDB, and DELL Today',\n",
       " 'Analysts recommendations: Best Buy, Dell Technologies, Moderna, AMD, National Grid...',\n",
       " 'State B Baseball: Dell Rapids survives late surge from Howard for the title',\n",
       " 'Dell Technologies PC Sales Begin Rebound, Server Sales Hit Record',\n",
       " 'Dell Technologies Expands Dell AI Factory with NVIDIA to Turbocharge AI Adoption',\n",
       " \"Dell Rapids wins pitchers' duel over Howard in Class B state high school baseball title game\",\n",
       " \"Nutanix's New Dell, Nvidia Alliances Meant To Advance AI, Multicloud\",\n",
       " \"Dell's Earnings: What It Means For The 2024 Market And AI Stocks\",\n",
       " 'Dell’s best cheap laptop just got $220 cheaper — only $280',\n",
       " 'Stocks making the biggest moves after hours: Dell Technologies, MongoDB, Zscaler, Gap and more',\n",
       " 'Why Dell’s stock had its worst day since 2018 despite strong AI demand',\n",
       " \"Dell Technologies Sales Boss Bill Scannell Says GenAI 'Opportunity Is Immense'\",\n",
       " 'Franklin Resources Inc. Has $2.58 Million Stock Position in Dell Technologies Inc. (NYSE:DELL)',\n",
       " 'Stock Market Today: Dow Jones Rises On Inflation Data; Dell Plunges 19% On Earnings',\n",
       " 'Dell cut the price of this Dell XPS 13 to $800 for a limited time',\n",
       " 'Best Dell XPS deals: Save on Dell XPS 13, Dell XPS 15 and Dell XPS 17',\n",
       " 'Dell stock plummets 20% because its AI play is falling short',\n",
       " 'Dell’s XPS, Inspiron, and Latitude laptops are getting Qualcomm chips',\n",
       " 'Dell earnings show fervent AI demand, but margin talk sends stock sliding',\n",
       " '‘Went south out of nowhere,’ says Tank Dell as Houston Texans star opens up on mass shooting that left him...',\n",
       " \"Gabrielle Dell'Otto's AMAZING SPIDER-MAN Variant Covers Pit The Wall-Crawler Against The Sinister Six\",\n",
       " 'The best Dell laptop 2024',\n",
       " '5 Big Dell Technologies World Announcements: AI Factory With Nvidia, AI Networking, Storage And PCs, PowerStore ...',\n",
       " 'Dell Memorial Day Sale 2024: The Best Deals on Dell and Alienware Gaming Laptops and PCs',\n",
       " 'U.S. Army Veteran Floyd Dell Woods Dies at 58',\n",
       " 'STATE B BASEBALL: Parkston/Ethan/Tripp, Dell Rapids, Howard & Mount Vernon/Plankinton/Corsica-Stickney advance through quarterfinals',\n",
       " \"Dell Rapids wins the class 'B' state championship\",\n",
       " 'Should You Buy Dell Technologies (DELL) Ahead of Q1 Earnings?',\n",
       " 'Dell: Nonlinear demand, chip supply curb our AI server growth']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape google news\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the URL of the Google News page\n",
    "#url = \"https://news.google.com/search?q=bitcoin&hl=en-US&gl=US&ceid=US%3Aen\"\n",
    "url = \"https://news.google.com/search?q=dell&hl=en-US&gl=US&ceid=US%3Aen\"\n",
    "\n",
    "# Fetch the HTML content of the page\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "headlines = soup.find_all('a', class_='JtKRv')\n",
    "\n",
    "# Print all the headlines\n",
    "all_headlines = []\n",
    "for headline in headlines:\n",
    "    all_headlines.append(headline.text)\n",
    "\n",
    "all_headlines\n",
    "# Optionally, extract URLs of the news articles\n",
    "#for headline in headlines:\n",
    "#    print(f\"https://news.google.com{headline['href'][1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are the best financial analyst in the world. You were educated at Harvard and have been working in the industry for 20 years.\n",
    "These are the headlines of Google News articles about Dell:\n",
    "Headlines: {string}\n",
    "Task: Provide me with an analysis if I should buy the stock for an long term investment.\"\"\"\n",
    "\n",
    "prompt_custom = PromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "rag_chain = (\n",
    "    {\"string\": RunnablePassthrough()}\n",
    "    | prompt_custom\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "result_1 = rag_chain.invoke({\"string\": all_headlines})\n",
    "\n",
    "## If results should be streamed\n",
    "# for chunk in rag_chain.stream(all_headlines):\n",
    "#     print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the headlines provided, it seems that Dell's stock has been experiencing significant fluctuations due to a variety of factors, including AI investments, earnings reports, and margin concerns. While Dell has shown strong demand for AI products, the impact on margins and earnings has caused volatility in the stock price.\\n\\nAs a financial analyst with 20 years of experience, I would recommend conducting a thorough analysis of Dell's financial statements, performance metrics, and industry outlook before making a decision on a long-term investment in Dell stock. It is important to consider factors such as revenue growth, profitability, competitive positioning, and future growth potential.\\n\\nAdditionally, it may be beneficial to monitor Dell's progress in addressing margin concerns related to AI investments and to assess the company's ability to capitalize on the growing demand for AI products.\\n\\nOverall, while Dell's stock may present opportunities for long-term investment, it is important to carefully evaluate all relevant information and factors before making a decision. It is always recommended to consult with a financial advisor or conduct further research before making any investment decisions.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitcoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2024-03-06  119.449997  120.559998  116.959999  118.500000  118.040939   \n",
      "2024-03-07  120.000000  122.019997  119.309998  120.500000  120.033188   \n",
      "2024-03-08  120.290001  120.769997  114.949997  116.250000  115.799652   \n",
      "2024-03-11  115.480003  116.830002  113.629997  115.860001  115.411163   \n",
      "2024-03-12  117.300003  118.290001  113.400002  113.550003  113.110115   \n",
      "\n",
      "              Volume  \n",
      "Date                  \n",
      "2024-03-06  10569100  \n",
      "2024-03-07   9644300  \n",
      "2024-03-08  11006600  \n",
      "2024-03-11   5936800  \n",
      "2024-03-12   6570000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def download_bitcoin_data():\n",
    "    # Define the ticker symbol for Bitcoin\n",
    "    ticker_symbol = 'DELL'\n",
    "\n",
    "    # Calculate the start and end dates\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=90)\n",
    "\n",
    "    # Download the data\n",
    "    bitcoin_data = yf.download(ticker_symbol, start=start_date, end=end_date, interval='1d')\n",
    "\n",
    "    return bitcoin_data\n",
    "\n",
    "bitcoin_data = download_bitcoin_data()\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(bitcoin_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are the best chart analyst in the world. You were educated at Harvard and have been working in the industry for 20 years.\n",
    "These is the market data for Dell at an daily interval for the past three days:\n",
    "Data: {string}\n",
    "Task: Provide me with an chart analysis if I should buy the DELL stock today. Calculate moving averages and other indicators if necessary. YOU NEED TO PROVIDE ME WITH AN DECISION THAT IS BUY OR NOT\"\"\"\n",
    "\n",
    "prompt_custom = PromptTemplate.from_template(template)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"string\": RunnablePassthrough()}\n",
    "    | prompt_custom\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "result_2 = rag_chain.invoke({\"string\": bitcoin_data})\n",
    "\n",
    "# for chunk in rag_chain.stream(all_headlines):\n",
    "#     print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the market data provided for Dell over the past three months, it is recommended to not buy the stock today. Here's why:\\n\\n1. Moving Averages: Looking at the data, we can calculate the moving averages for Dell. The most commonly used moving averages are the 50-day and 200-day moving averages. If the current price is below both the 50-day and 200-day moving averages, it indicates a bearish trend and suggests not to buy the stock.\\n\\n2. Price Trend: The closing price of Dell has been fluctuating over the past three months, showing a lack of clear direction in the price trend. This uncertainty in price movement may not be favorable for buying the stock at this time.\\n\\n3. Volume: The trading volume for Dell has also been inconsistent, which could indicate a lack of significant interest or conviction from investors in the stock.\\n\\nIn conclusion, considering the moving averages, price trend, and trading volume, it is not advisable to buy Dell stock today. It is recommended to wait for a more stable and positive trend before considering an investment in Dell.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are the best financial analyst in the world. You were educated at Harvard and have been working in the industry for 60 years.\n",
    "You have been a math prodigy as a kid. You did research with Daniel Kahneman and won the Nobel Prize in Economics.\n",
    "Two of your analysts have come up with predictions for the Bitcoin price in the next three days.\n",
    "Analyst 1: {string_1}\n",
    "Analyst 2: {string_2}\n",
    "Task: You have to decide if we are going to buy DELL stock.\"\"\"\n",
    "\n",
    "prompt_custom = PromptTemplate.from_template(template)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"string_1\": RunnablePassthrough(), \"string_2\": RunnablePassthrough()}\n",
    "    | prompt_custom\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "result = rag_chain.invoke({\"string_1\": result_1, \"string_2\": result_2})\n",
    "\n",
    "# for chunk in rag_chain.stream(all_headlines):\n",
    "#     print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the analysis provided by both analysts, it is recommended not to buy Dell stock today. The factors such as moving averages, price trend, and trading volume suggest a lack of clear direction and stability in the stock's performance. It would be prudent to wait for a more stable and positive trend before considering an investment in Dell.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content=\"\\n\\n\\n\\n\\nLangSmith User Guide | 🦜️🛠️ LangSmith\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentLangSmith API DocsSearchGo to AppQuick StartUser GuideTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyPricingSelf-HostingCookbookThis is outdated documentation for 🦜️🛠️ LangSmith, which is no longer actively maintained.For up-to-date documentation, see the latest version.User GuideOn this pageLangSmith User GuideLangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.Prototyping\\u200bPrototyping LLM applications often involves quick experimentation between prompts, model types, retrieval strategy and other parameters.\\nThe ability to rapidly understand how the model is performing — and debug where it is failing — is incredibly important for this phase.Debugging\\u200bWhen developing new LLM applications, we suggest having LangSmith tracing enabled by default.\\nOftentimes, it isn’t necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), it’s extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\\nWe provide native rendering of chat messages, functions, and retrieve documents.Initial Test Set\\u200bWhile many developers still ship an initial version of their application based on “vibe checks”, we’ve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\\nThese test cases can be uploaded in bulk, created on the fly, or exported from application traces. LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results.Comparison View\\u200bWhen prototyping different versions of your applications and making changes, it’s important to see whether or not you’ve regressed with respect to your initial test cases.\\nOftentimes, changes in the prompt, retrieval strategy, or model choice can have huge implications in responses produced by your application.\\nIn order to get a sense for which variant is performing better, it’s useful to be able to view results for different configurations on the same datapoints side-by-side. We’ve invested heavily in a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.Playground\\u200bLangSmith provides a playground environment for rapid iteration and experimentation.\\nThis allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.\\nEvery playground run is logged in the system and can be used to create test cases or compare with other runs.Beta Testing\\u200bBeta testing allows developers to collect more data on how their LLM applications are performing in real-world scenarios. In this phase, it’s important to develop an understanding for the types of inputs the app is performing well or poorly on and how exactly it’s breaking down in those cases. Both feedback collection and run annotation are critical for this workflow. This will help in curation of test cases that can help track regressions/improvements and development of automatic evaluations.Capturing Feedback\\u200bWhen launching your application to an initial set of users, it’s important to gather human feedback on the responses it’s producing. This helps draw attention to the most interesting runs and highlight edge cases that are causing problematic responses. LangSmith allows you to attach feedback scores to logged traces (oftentimes, this is hooked up to a feedback button in your app), then filter on traces that have a specific feedback tag and score. A common workflow is to filter on traces that receive a poor user feedback score, then drill down into problematic points using the detailed trace view.Annotating Traces\\u200bLangSmith also supports sending runs to annotation queues, which allow annotators to closely inspect interesting traces and annotate them with respect to different criteria. Annotators can be PMs, engineers, or even subject matter experts. This allows users to catch regressions across important evaluation criteria.Adding Runs to a Dataset\\u200bAs your application progresses through the beta testing phase, it's essential to continue collecting data to refine and improve its performance. LangSmith enables you to add runs as examples to datasets (from both the project page and within an annotation queue), expanding your test coverage on real-world scenarios. This is a key benefit in having your logging system and your evaluation/testing system in the same platform.Production\\u200bClosely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows you’ll also want to do once your app hits production.However, especially at the production stage, it’s crucial to get a high-level overview of application performance with respect to latency, cost, and feedback scores. This ensures that it's delivering desirable results at scale.Online evaluations and automations allow you to process and score production traces in near real-time.Additionally, threads provide a seamless way to group traces from a single conversation, making it easier to track the performance of your application across multiple turns.Monitoring and A/B Testing\\u200bLangSmith provides monitoring charts that allow you to track key metrics over time. You can expand to view metrics for a given period and drill down into a specific data point to get a trace table for that time period — this is especially handy for debugging production issues.LangSmith also allows for tag and metadata grouping, which allows users to mark different versions of their applications with different identifiers and view how they are performing side-by-side within each chart. This is helpful for A/B testing changes in prompt, model, or retrieval strategy.Automations\\u200bAutomations are a powerful feature in LangSmith that allow you to perform actions on traces in near real-time. This can be used to automatically score traces, send them to annotation queues, or send them to datasets.To define an automation, simply provide a filter condition, a sampling rate, and an action to perform. Automations are particularly helpful for processing traces at production scale.Threads\\u200bMany LLM applications are multi-turn, meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation together, making it easier to track the performance of and annotate your application across multiple turns.Was this page helpful?You can leave detailed feedback on GitHub.PreviousQuick StartNextOverviewPrototypingBeta TestingProductionCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.\\n\\n\\n\\n\", metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}), Document(page_content='\\n\\n\\n\\n\\nGet started with LangSmith | 🦜️🛠️ LangSmith\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmith\\u200bPythonTypeScriptpip install -U langsmithyarn add langchain langsmith2. Create an API key\\u200bTo create an API key head to the Settings page. Then click Create API Key.3. Set up your environment\\u200bShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it\\'s not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>4. Log your first trace\\u200bWe provide multiple ways to log traces to LangSmith. Below, we\\'ll highlight\\nhow to use traceable. See more on the Annotate code for tracing page.PythonTypeScriptimport openaifrom langsmith.wrappers import wrap_openaifrom langsmith import traceable# Auto-trace LLM calls in-contextclient = wrap_openai(openai.Client())@traceable # Auto-trace this functiondef pipeline(user_input: str):    result = client.chat.completions.create(        messages=[{\"role\": \"user\", \"content\": user_input}],        model=\"gpt-3.5-turbo\"    )    return result.choices[0].message.contentpipeline(\"Hello, world!\")# Out:  Hello there! How can I assist you today?import { OpenAI } from \"openai\";import { traceable } from \"langsmith/traceable\";import { wrapOpenAI } from \"langsmith/wrappers\";// Auto-trace LLM calls in-contextconst client = wrapOpenAI(new OpenAI());// Auto-trace this functionconst pipeline = traceable(async (user_input) => {    const result = await client.chat.completions.create({        messages: [{ role: \"user\", content: user_input }],        model: \"gpt-3.5-turbo\",    });    return result.choices[0].message.content;});await pipeline(\"Hello, world!\")// Out: Hello there! How can I assist you today?View a sample output trace.Learn more about tracing in the how-to guides.5. Run your first evaluation\\u200bEvaluation requires a system to test, data to serve as test cases, and optionally evaluators to grade the results. Here we use a built-in accuracy evaluator.PythonTypeScriptfrom langsmith import Clientfrom langsmith.evaluation import evaluateclient = Client()# Define dataset: these are your test casesdataset_name = \"Sample Dataset\"dataset = client.create_dataset(dataset_name, description=\"A sample dataset in LangSmith.\")client.create_examples(    inputs=[        {\"postfix\": \"to LangSmith\"},        {\"postfix\": \"to Evaluations in LangSmith\"},    ],    outputs=[        {\"output\": \"Welcome to LangSmith\"},        {\"output\": \"Welcome to Evaluations in LangSmith\"},    ],    dataset_id=dataset.id,)# Define your evaluatordef exact_match(run, example):    return {\"score\": run.outputs[\"output\"] == example.outputs[\"output\"]}experiment_results = evaluate(    lambda input: \"Welcome \" + input[\\'postfix\\'], # Your AI system goes here    data=dataset_name, # The data to predict and grade over    evaluators=[exact_match], # The evaluators to score the results    experiment_prefix=\"sample-experiment\", # The name of the experiment    metadata={      \"version\": \"1.0.0\",      \"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },    { postfix: \"to Evaluations in LangSmith\" },  ],  outputs: [    { output: \"Welcome to LangSmith\" },    { output: \"Welcome to Evaluations in LangSmith\" },  ],  datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async (  run: Run,  example: Example): Promise<EvaluationResult> => {  return {    key: \"exact_match\",    score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators: [exactMatch],    metadata: {      version: \"1.0.0\",      revision_id: \"beta\",    },  });Learn more about evaluation in the how-to guides.Was this page helpful?You can leave detailed feedback on GitHub.NextTutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.\\n\\n\\n\\n', metadata={'source': 'https://docs.smith.langchain.com', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en'})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Multiple URLs\n",
    "website_urls = [\n",
    "    \"https://docs.smith.langchain.com/user_guide\",\n",
    "    \"https://docs.smith.langchain.com\",\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store all documents\n",
    "all_documents = []\n",
    "\n",
    "# Loop through website URLs and use WebBaseLoader for each\n",
    "for url in website_urls:\n",
    "  loader = WebBaseLoader(url)\n",
    "  website_documents = loader.load()\n",
    "  all_documents.extend(website_documents)\n",
    "\n",
    "# Process the all_documents list further (e.g., vectorization)\n",
    "\n",
    "print(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Load openAI embedding model to get the embeddings of the documents\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Add vector store\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(all_documents)\n",
    "vector_store = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<faiss.swigfaiss.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x7f7aa0bb6d20> >\n",
      "Vector 0: [-0.0080638   0.01916084  0.01222096 ... -0.00213274  0.02612103\n",
      " -0.01153036]\n",
      "Vector 1: [-0.02374188  0.01507666  0.00888921 ...  0.01401275  0.00637293\n",
      " -0.01765243]\n",
      "Vector 2: [-0.01742077  0.01093862  0.01232167 ...  0.00759277 -0.00432376\n",
      " -0.01816119]\n",
      "Vector 3: [-0.021696    0.01003824  0.01190209 ... -0.00271375 -0.0079929\n",
      " -0.03096637]\n",
      "Vector 4: [ 0.00756025  0.01780557  0.01517474 ...  0.00688559  0.0135542\n",
      " -0.00869937]\n",
      "Vector 5: [ 0.00599423  0.00548193  0.00797372 ...  0.01548741  0.00085122\n",
      " -0.02121678]\n",
      "Vector 6: [-0.00539542  0.00660179  0.00760884 ... -0.00329915 -0.01941374\n",
      " -0.05169536]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve vectors from the vector store\n",
    "\n",
    "# This is the underlying FAISS index\n",
    "faiss_index = vector_store.index\n",
    "print(faiss_index)\n",
    "\n",
    "# 0 is the starting index and faiss_index.ntotal is the ending index\n",
    "vectors = faiss_index.reconstruct_n(0, faiss_index.ntotal)\n",
    "for i, vector in enumerate(vectors):\n",
    "    print(f\"Vector {i}: {vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context'] template='Use the following pieces of context to answer the question at the end.\\nIf you don\\'t know the answer, just say that you don\\'t know. Use three sentences maximum and keep the answer as concise as possible.\\nAlways say \"thanks for asking!\" at the end of the answer.\\n{context}\\nQuestion: What is task decomposition in project management?\\nHelpful Answer:'\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "#We can use PromptTemplate to add more instructions to our input for the LLM, (instructions, context from retriever and the question user wants to ask)\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "prompt_custom = PromptTemplate.from_template(template)\n",
    "\n",
    "print(prompt_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7f7ab1501fa0>)\n",
       "           | RunnableLambda(format_docs)\n",
       "}\n",
       "| PromptTemplate(input_variables=['context'], template='Use the following pieces of context to answer the question at the end.\\nIf you don\\'t know the answer, just say that you don\\'t know. Use three sentences maximum and keep the answer as concise as possible.\\nAlways say \"thanks for asking!\" at the end of the answer.\\n{context}\\nQuestion: What is task decomposition in project management?\\nHelpful Answer:')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f7ac0be51c0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f7ac0bed940>, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs}\n",
    "    | prompt_custom\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "#print(rag_chain)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
